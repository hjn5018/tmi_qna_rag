import re
from langchain_core.documents import Document
from langchain_text_splitters import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

from dotenv import load_dotenv

load_dotenv()

# ê²½ë¡œ ì„¤ì •
KAKAO_PATH = "data/kakao_chat.txt"
VECTOR_DB_PATH = "db/tmi_faiss"

# ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ ì •ê·œì‹ íŒ¨í„´
MESSAGE_PATTERN = re.compile(r"\[(.*?)\] \[(.*?)\] (.+)")

def load_kakao_chat(filepath):
    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    documents = []
    current_date = ""
    for line in lines:
        line = line.strip()

        # ë‚ ì§œ ë¼ì¸
        if "---------------" in line:
            date_match = re.search(r"\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼", line)
            if date_match:
                current_date = date_match.group(0)
            continue

        match = MESSAGE_PATTERN.match(line)
        if match:
            sender, time, content = match.groups()
            full_message = f"{current_date} {time} | {sender}: {content}"
            documents.append(Document(page_content=full_message))

    return documents

def ingest_kakao():
    print("ğŸ“¥ kakao_chat.txt ì½ëŠ” ì¤‘...")
    docs = load_kakao_chat(KAKAO_PATH)

    print(f"ğŸ”¢ ì „ì²´ ë©”ì‹œì§€ ìˆ˜: {len(docs)}")
    splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0)
    split_docs = splitter.split_documents(docs)

    embedding = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(split_docs, embedding)
    vectorstore.save_local(VECTOR_DB_PATH)
    print("âœ… ë²¡í„° ì €ì¥ ì™„ë£Œ:", VECTOR_DB_PATH)

    # print("ğŸ’¬ ì˜ˆì‹œ ë©”ì‹œì§€:")
    # for d in docs[:5]:
    #     print(d.page_content)


if __name__ == "__main__":
    ingest_kakao()
    