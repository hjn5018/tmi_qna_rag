import streamlit as st
import sqlite3
import re
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud
from datetime import datetime
from dotenv import load_dotenv

from langchain_core.documents import Document
from langchain_text_splitters import CharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.messages import SystemMessage, HumanMessage

load_dotenv()

config = {
    "kakao_path": "data/kakao_chat.txt",
    "csv_path": "data/tmi.csv",
    "db_path": "db/chat_history.db",
    "vector_path": "db/tmi_faiss",
    "chunk_size": 500,
    "chunk_overlap": 20,
    "llm_model": "gpt-3.5-turbo",
    "chat_history_limit": 10,
    "font_path": "malgun.ttf",  # mac ì‚¬ìš©ìëŠ” "NanumGothic.ttf" ë“±ìœ¼ë¡œ êµì²´
}

def load_kakao_chat(filepath):
    with open(filepath, encoding="utf-8") as f:
        lines = f.readlines()

    documents = []
    current_date = ""
    msg_pattern = re.compile(r"\[(.*?)\] \[(.*?)\] (.+)")

    for line in lines:
        line = line.strip()
        if "---------------" in line:
            date_match = re.search(r"\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼", line)
            if date_match:
                current_date = date_match.group(0)
            continue

        match = msg_pattern.match(line)
        if match:
            sender, time, content = match.groups()
            full_msg = f"ë‚ ì§œ: {current_date}, ì‹œê°„: {time}, ë³´ë‚¸ì´: {sender}\në‚´ìš©: {content}"
            documents.append(Document(page_content=full_msg))

    return documents

def load_kakao_text(filepath):
    with open(filepath, encoding="utf-8") as f:
        return f.read()

def load_tmi_csv(filepath):
    df = pd.read_csv(filepath)
    return [Document(page_content=row["tmi"]) for _, row in df.iterrows()]

def load_all_documents():
    kakao_docs = load_kakao_chat(config["kakao_path"])
    tmi_docs = load_tmi_csv(config["csv_path"])
    return kakao_docs + tmi_docs

def build_vectorstore(documents):
    splitter = CharacterTextSplitter(chunk_size=config["chunk_size"], chunk_overlap=config["chunk_overlap"])
    split_docs = splitter.split_documents(documents)

    embedding = OpenAIEmbeddings()
    vectorstore = FAISS.from_documents(split_docs, embedding)
    vectorstore.save_local(config["vector_path"])
    return vectorstore

def save_chat(question, answer):
    conn = sqlite3.connect(config["db_path"])
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS chat_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            question TEXT,
            answer TEXT,
            timestamp TEXT
        )
    """)
    cursor.execute(
        "INSERT INTO chat_log (question, answer, timestamp) VALUES (?, ?, ?)",
        (question, answer, datetime.now().isoformat())
    )
    conn.commit()
    conn.close()

def load_chat_history(limit=None):
    conn = sqlite3.connect(config["db_path"])
    cursor = conn.cursor()
    limit_clause = f"LIMIT {limit}" if limit else ""
    cursor.execute(f"SELECT question, answer FROM chat_log ORDER BY id DESC {limit_clause}")
    rows = cursor.fetchall()
    conn.close()
    return rows[::-1]

def answer_query(query, vectorstore):
    retriever = vectorstore.as_retriever()
    related_docs = retriever.invoke(query)
    tmi_context = "\n".join([doc.page_content for doc in related_docs]) or "(ê´€ë ¨ ì •ë³´ ì—†ìŒ)"

    include_history = any(k in query for k in ["ì´ì „", "ì „ì—", "ê¸°ì–µ", "í–ˆì—ˆ", "í–ˆë‹ˆ", "ëŒ€í™”", "ê³¼ê±°", "ë¬´ìŠ¨ ì§ˆë¬¸"])
    history_text = ""
    if include_history:
        history = load_chat_history(limit=config["chat_history_limit"])
        history_text = "\n".join([f"User: {q}\nAssistant: {a}" for q, a in history])

    messages = [
        SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  êµ¬ì²´ì ì¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."),
        HumanMessage(content=f"""# ğŸ“˜ TMI ë° ëŒ€í™” ë°ì´í„°:
{tmi_context}

{f"# ğŸ“œ ì´ì „ ëŒ€í™”:\n{history_text}" if history_text else ""}
# ğŸ¤” ì§ˆë¬¸:
{query}""")
    ]

    llm = ChatOpenAI(model=config["llm_model"])
    response = llm.invoke(messages)
    return response.content.strip()

# === ê°•ì•„ì§€ ì´ë¦„ ë¶„ì„ ===
def extract_dog_names_with_llm(kakao_text: str) -> list:
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
    example = (
        "[ã…ã…] [ì˜¤í›„ 8:44] í‘¸ë“¤ í•œ ì•„ì´ëŠ” ì§‘ì— ê°€ê³  ì‘ê³  ê¹Œë¶ˆê¹Œë¶ˆí•˜ëŠ” í‘¸ë“¤ê³¼ ì¼ìš”ì¼ê¹Œì§€ ê°™ì´ ìˆìŠµë‹ˆë‹¤~\n"
        "[ã…ã…] [ì˜¤í›„ 9:04] ëª‡ ë²ˆ ë§Œë‚œ ì  ìˆëŠ” ì†Œì‹¬í•œ í¬ë©” ì—¬ì•„ê°€ ì™”ìŠµë‹ˆë‹¤.\n"
        "[ã…ã…] [ì˜¤ì „ 11:31] ì¥ê³ ë‘ ì‚°ì±…í•˜ê³  ì™”ì–´ìš”\n"
        "[ã…ã…] [ì˜¤ì „ 11:32] ë£¨ì´ë„ ê°™ì´ ìˆì—ˆì–´ìš”\n"
    )
    system_prompt = (
        "ë‹¤ìŒì€ ê°•ì•„ì§€ì— ëŒ€í•œ ì¹´ì¹´ì˜¤í†¡ ëŒ€í™”ì…ë‹ˆë‹¤.\n"
        "- ê°•ì•„ì§€ëŠ” ì£¼ë¡œ ì‚°ì±…í•˜ê±°ë‚˜ ì‚¬ì§„ì— ì°íˆê±°ë‚˜ ê°„ì‹ì„ ë°›ìŠµë‹ˆë‹¤.\n"
        "- ì‚¬ëŒ ì´ë¦„, ë‚ ì§œ, ì¥ì†Œ, ì‹œê°„ í‘œí˜„ì€ ì œì™¸í•˜ì„¸ìš”.\n"
        "- ê°•ì•„ì§€ ì´ë¦„ë§Œ Python ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”. ì˜ˆ: ['ì¥ê³ ', 'ë£¨ì´', 'í¬ë©”', 'í‘¸ë“¤']\n"
    )

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=example + kakao_text[:3000])
    ]

    response = llm.invoke(messages)
    try:
        names = eval(response.content.strip())
        return [n for n in names if isinstance(n, str) and re.fullmatch(r"[ê°€-í£]{2,4}", n)]
    except:
        return []

def count_name_occurrences(text, name_list):
    words = re.findall(r"[ê°€-í£]{2,}", text)
    return Counter([w for w in words if w in name_list])

def plot_wordcloud(counter):
    if not counter:
        st.warning("ê°ì§€ëœ ì´ë¦„ì´ ì—†ì–´ìš”.")
        return
    wc = WordCloud(
        font_path=config["font_path"],
        background_color="white",
        width=800,
        height=400
    ).generate_from_frequencies(counter)

    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    st.pyplot(plt)

# === Streamlit ì•± ì‹¤í–‰ ===
def run_app():
    st.set_page_config(page_title="TMI ì±—ë´‡", layout="centered")
    tab1, tab2 = st.tabs(["ğŸ’¬ TMI ì±—ë´‡", "ğŸ¶ ê°•ì•„ì§€ ì´ë¦„ ë¶„ì„"])

    # === TAB 1: ì±—ë´‡ ===
    with tab1:
        st.header("ğŸ’¬ TMI ì±—ë´‡")

        if "vectorstore" not in st.session_state:
            docs = load_all_documents()
            st.session_state.vectorstore = build_vectorstore(docs)

        if "history" not in st.session_state:
            st.session_state.history = []

        query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", "")

        if st.button("ì§ˆë¬¸í•˜ê¸°") and query.strip():
            with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                answer = answer_query(query, st.session_state.vectorstore)
                save_chat(query, answer)
                st.session_state.history.append((query, answer))

        if st.session_state.history:
            st.write("## ëŒ€í™” ê¸°ë¡")
            for i, (q, a) in enumerate(st.session_state.history):
                st.markdown(f"**Q{i+1}:** {q}")
                st.markdown(f"**A{i+1}:** {a}")

    # === TAB 2: ê°•ì•„ì§€ ì´ë¦„ ì›Œë“œí´ë¼ìš°ë“œ ===
    with tab2:
        st.header("ğŸ¶ ì¹´ì¹´ì˜¤í†¡ ì† ê°•ì•„ì§€ ì´ë¦„ ì›Œë“œí´ë¼ìš°ë“œ@@@@")
        if st.button("ê°•ì•„ì§€ ì´ë¦„ ë¶„ì„ ì‹œì‘"):
            with st.spinner("LLMì´ ê°•ì•„ì§€ ì´ë¦„ì„ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤..."):
                kakao_text = load_kakao_text(config["kakao_path"])
                dog_names = extract_dog_names_with_llm(kakao_text)

                if dog_names:
                    st.success(f"ê°•ì•„ì§€ ì´ë¦„: {', '.join(dog_names)}")
                    counts = count_name_occurrences(kakao_text, dog_names)
                    st.write("### ğŸ“Š ì´ë¦„ë³„ ë“±ì¥ íšŸìˆ˜")
                    st.json(dict(counts))
                    st.write("### â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
                    plot_wordcloud(counts)
                else:
                    st.warning("ê°•ì•„ì§€ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ì—ˆì–´ìš”.")

if __name__ == "__main__":
    run_app()
